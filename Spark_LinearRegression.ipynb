{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dd8cfe18",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f6832f4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.regression import GeneralizedLinearRegression\n",
    "\n",
    "#from pyspark import SparkConf, SparkContext\n",
    "#sc = SparkContext(conf=SparkConf().set(\"spark.files.overwrite\", \"true\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "96d3bc2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/09/23 19:29:58 WARN Utils: Your hostname, cesar-GL62M-7RDX resolves to a loopback address: 127.0.1.1; using 10.22.162.210 instead (on interface wlp2s0)\n",
      "22/09/23 19:29:58 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "22/09/23 19:29:59 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession\\\n",
    "        .builder\\\n",
    "        .appName(\"GeneralizedLinearRegressionExample\")\\\n",
    "        .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e3826fe",
   "metadata": {},
   "source": [
    "# User-Defined functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e543a74e",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9913bc92",
   "metadata": {},
   "outputs": [],
   "source": [
    "def spark_from_url(url, num_features = False):\n",
    "    \n",
    "    file_name = url[url.rfind('/')+1:]\n",
    "    \n",
    "    from pyspark import SparkFiles\n",
    "    spark.sparkContext.addFile(url)\n",
    "    \n",
    "    if num_features !=False:\n",
    "        dataset = spark.read.format(\"libsvm\").option(\"numFeatures\", num_features).load(\"file://\"+SparkFiles.get(file_name))\n",
    "    else:\n",
    "        dataset = spark.read.format(\"libsvm\").load(\"file://\"+SparkFiles.get(file_name))\n",
    "    \n",
    "    return dataset\n",
    "\n",
    "# Test:\n",
    "if False:\n",
    "    dataset = spark_from_url(url, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94819410",
   "metadata": {},
   "source": [
    "# Linear regression examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dae9a816",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://raw.githubusercontent.com/apache/spark/master/data/mllib/sample_linear_regression_data.txt\"\n",
    "dataset = spark_from_url(url, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "62302511",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients: [0.010541828081257209,0.800325310056095,-0.7845165541420372,2.3679887171421914,0.5010002089857577,1.1222351159753023,-0.2926824398623297,-0.49837174323213046,-0.6035797180675657,0.6725550067187459]\n",
      "\n",
      "Intercept: 0.14592176145232047\n",
      "\n",
      "Coefficient Standard Errors: [0.7950428434287478, 0.8049713176546897, 0.7975916824772489, 0.831264924765992, 0.7945436200517938, 0.8118992572197593, 0.7919506385542777, 0.7973378214726764, 0.8300714999626418, 0.7771333489686802, 0.463930109648428]\n",
      "\n",
      "T Values: [0.013259446542269234, 0.9942283563442595, -0.9836067393599173, 2.8486570846337584, 0.6305509179635714, 1.3822344410293548, -0.36957156874906694, -0.6250446546128239, -0.7271418403049983, 0.8654306337661118, 0.314533931765933]\n",
      "\n",
      "P Values: [0.989426199114056, 0.32060241580811044, 0.3257943227369877, 0.004575078538306521, 0.5286281628105467, 0.16752945248679119, 0.7118614002322872, 0.5322327097421431, 0.467486325282384, 0.3872259825794293, 0.753249430501097]\n",
      "\n",
      "Dispersion: 105.60988356821714\n",
      "\n",
      "Null Deviance: 53229.3654338832\n",
      "\n",
      "Residual Degree Of Freedom Null: 500\n",
      "\n",
      "Deviance: 51748.8429484264\n",
      "\n",
      "Residual Degree Of Freedom: 490\n",
      "\n",
      "AIC: 3769.1895871765314\n",
      "\n",
      "Deviance Residuals: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cesar/anaconda3/envs/hdl/lib/python3.8/site-packages/pyspark/sql/context.py:125: FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+\n",
      "|  devianceResiduals|\n",
      "+-------------------+\n",
      "|-10.974359174246889|\n",
      "| 0.8872320138420557|\n",
      "| -4.596541837478908|\n",
      "|-20.411667435019638|\n",
      "|-10.270419345342642|\n",
      "|-6.0156058956799905|\n",
      "|-10.663939415849267|\n",
      "| 2.1153960525024713|\n",
      "|  3.980713237913768|\n",
      "|-17.225218272069533|\n",
      "| -4.611647633532146|\n",
      "|  6.417666940769855|\n",
      "| 11.407137945300537|\n",
      "| -20.70176540467664|\n",
      "| -2.683748540510967|\n",
      "|-16.755494794232536|\n",
      "|  8.154668342638725|\n",
      "|-1.4355057987358848|\n",
      "|  -0.64350586881857|\n",
      "|-1.1380258931683198|\n",
      "+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "glr = GeneralizedLinearRegression(family=\"gaussian\", link=\"identity\", maxIter=10, regParam=0.3)\n",
    "\n",
    "# Fit the model\n",
    "model = glr.fit(dataset)\n",
    "\n",
    "# Print the coefficients and intercept for generalized linear regression model\n",
    "print(\"Coefficients: \" + str(model.coefficients) + \"\\n\")\n",
    "print(\"Intercept: \" + str(model.intercept) + \"\\n\")\n",
    "\n",
    "# Summarize the model over the training set and print out some metrics\n",
    "summary = model.summary\n",
    "print(\"Coefficient Standard Errors: \" + str(summary.coefficientStandardErrors) + \"\\n\")\n",
    "print(\"T Values: \" + str(summary.tValues) + \"\\n\")\n",
    "print(\"P Values: \" + str(summary.pValues) + \"\\n\")\n",
    "print(\"Dispersion: \" + str(summary.dispersion) + \"\\n\")\n",
    "print(\"Null Deviance: \" + str(summary.nullDeviance) + \"\\n\")\n",
    "print(\"Residual Degree Of Freedom Null: \" + str(summary.residualDegreeOfFreedomNull) + \"\\n\")\n",
    "print(\"Deviance: \" + str(summary.deviance) + \"\\n\")\n",
    "print(\"Residual Degree Of Freedom: \" + str(summary.residualDegreeOfFreedom) + \"\\n\")\n",
    "print(\"AIC: \" + str(summary.aic) + \"\\n\")\n",
    "print(\"Deviance Residuals: \")\n",
    "summary.residuals().show()\n",
    "\n",
    "spark.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccfd063d",
   "metadata": {},
   "source": [
    "# Sources\n",
    "* [Test Data](https://github.com/apache/spark/blob/master/data/mllib/sample_linear_regression_data.txt)\n",
    "* [Generalized Linear Regression Example](https://github.com/apache/spark/blob/master/examples/src/main/python/ml/generalized_linear_regression_example.py)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
